#Logistic Regression

# This is to give an example of logistic regression in R. Data from Kaggle Titanic dataset and following
# tutorial from https://datascienceplus.com/perform-logistic-regression-in-r/

# Clear environment and load any libaries

rm(list=ls())

setwd("D:/R Codes/Titanic Data")

# Import dataset

training.data.raw <- read.csv("train.csv",header=T, na.strings=c(""))


# Count number of missing and number of unique responeses
sapply(training.data.raw, function(x) sum(is.na(x)))
sapply(training.data.raw, function(x) length(unique(x)))


#Plot missing values vs observed
#install.packages("Amelia")
library('Amelia')
missmap(training.data.raw, main="Missing values vs Observed")


#Subset to remove cabin (too many missing), Name (as adds no value), 
#passenger (just a counter field) and ticket (ticket Id)
data <- subset(training.data.raw, select = c(2,3,5,6,7,8,10,12))

#For missing Age values different approaches can be taken, either manually or using a substitute.
#With this example the average age will be given to all missing values (29.69912).

data$Age[is.na(data$Age)] <- mean(data$Age, na.rm=T)

#Checking whether categorical variables are stored as factors
is.factor(data$Sex)
is.factor(data$Embarked)

#Use this to determine how R will treat the categorical variables
contrasts(data$Sex)
contrasts(data$Embarked)

#There are 2 rows missing Embarked and so these rows will be disgarded
data <- data[!is.na(data$Embarked),]
rownames(data) <- NULL

#Data will be trainined on the first 800 rows and then the remainder will be used to test
#splitting the data into the two datasets

train<-data[1:800,]
test<-data[801:889,]

#Fitting a standard logistic regression to the trainin data
model<-glm(Survived ~.,family=binomial(link='logit'),data=train)
summary(model)

#From summary
#SibSp,Parch.Fare,Embacked are not statistically significant
#Sex has the lowest P value. Negative estimate means that all other values being equal males
#   had a lower chance of survival. With log odds, male reduces the log odds by 2.75 while each
#   age unit increase reduces log odds by 0.037.

#Running ANOVA to analyse the deviance
anova(model,test="Chisq")

#This shows the difference against the null model, only using the intercept. The wider the gap the better.
#Drop in deviance reduced significantly with addition of Pclass, Sex, Age. SibSp improves the model by a 
#   lesser extent due to the much higher but still statistically valid p value. Other values have large 
#   P values which inidicates that the model without the value is approximately the same.

#Generating R^2 value - no exact equivalent to linear regression R^2 but McFadden R^2 can be used to assess Fit
#install.packages("pscl")
library("pscl")
pR2(model)



#Assessing predictive capability

#Using model on test data
fitted.results <-predict(model,newdata=subset(test,select=c(2,3,4,5,6,7,8)))
#Where prob greater than 0.5 the person is deemed to have survived
fitted.results <- ifelse(fitted.results > 0.5,1,0)
#This generates the accuracy statistic
misClasificError <- mean(fitted.results != test$Survived)
print(paste('Accuracy',1-misClasificError))

#This is showing an accuracy of 79%.

#Generating the ROC curve and the AUC stat
#ROC is generated by plotting the true positive rate agaisnt the false positve rate. AUC is the area
#   under the curve. AUC closer to 1 is better

#install.packages("ROCR")
library("ROCR")

p<-predict(model, newdata=subset(test,select=c(2,3,4,5,6,7,8)),type="response")
pr<-prediction(p,test$Survived)
#TPR = sensitivity, FPR = specificity
prf<-performance(pr,measure="tpr", x.measure = "fpr")
plot(prf)

auc<-performance(pr,measure="auc")
auc<-auc@y.values[[1]]
print(auc)






#Changing model to no longer use SibSp,Parch.Fare,Embacked and basing it of the full dataset for predicting
  #survival in the unknown outcome dataset

model2<-glm(Survived ~.,family=binomial(link='logit'),subset(data,select=c(1,2,3,4)))
summary(model2)

#Importing unknown outcome dataset
uo.data.raw <- read.csv("test.csv",header=T, na.strings=c(""))

#dropping columns not needed and applying average age to null ages
uo<-subset(uo.data.raw, select =c(2,4,5))
uo$Age[is.na(uo$Age)] <- mean(uo$Age, na.rm=T)

#applying the model
prob<-predict(model2, newdata=uo, type="response")
predict<-ifelse(prob > 0.5,1,0)

#attaching prediction to uknown outcome dataset
predict.list<-as.data.frame(cbind(predict))
output<-cbind(uo.data.raw,predict.list)
final.prediction<-subset(output, select=c(1,12))

#bringing in the result dataset
final.result <- read.csv("gender_submission.csv",header=T, na.strings=c(""))

final.outcome<-merge(final.prediction, final.result)

final.outcome$Difference<-ifelse(final.outcome$predict != final.outcome$Survived,1,0)
Error <- mean(final.outcome$Difference)
print(paste('Accuracy',1-Error)) #Final Prediction Accuracy of 96.4%